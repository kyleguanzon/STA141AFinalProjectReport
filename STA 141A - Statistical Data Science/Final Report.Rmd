---
title: "Neural Activity and Behavioral Predictions: An Analysis of Behavioral Outcomes in Mice"
author: "Kyle Guanzon"
date: "2024-03-17"
output: 
  html_document:
    theme: yeti
    toc: true
    toc_float: true

---
```{r include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(tidyverse)
library(caret) 
library(xgboost)
library(pROC) # To create citations
```

# Abstract (5 pts).

  [ABSTRACT GOES HERE]

# Section 1 Introduction (5 pts).

  The intricate dance between sensory input and decision-making in mammals involves complex neural mechanisms, with the visual cortex playing a pivotal role in processing visual stimuli and guiding behavioral responses. In the seminal work of Steinmetz et al. (2019), the neural underpinnings of decision-making were explored through detailed experiments involving mice subjected to various visual stimuli, where the resulting neural activity was meticulously recorded. This study stands as a testament to the progress in our understanding of how the brain interprets and responds to sensory information, laying the groundwork for further exploration into the predictive capabilities of neural activity in relation to behavior.

  Despite the advances, a gap remains in our ability to predict behavioral outcomes based solely on the neural activity elicited by visual stimuli. The complexity of neural responses, coupled with the variability in individual and session-based responses, presents a significant challenge to developing predictive models with high accuracy and reliability. This project aims to bridge this gap by employing a comprehensive analysis of neural spike train data, alongside the stimuli conditions, to build a model capable of predicting the outcome of each trial in terms of success or failure.

  By focusing on the detailed spike trains of neurons in the visual cortex of mice and the conditions of the visual stimuli presented, this study seeks to uncover patterns and relationships that can inform our understanding of the neural basis of decision-making. Through a combination of exploratory data analysis, data integration techniques, and predictive modeling, this project endeavors to enhance our predictive capabilities, providing insights that could have broad implications for neuroscience, particularly in understanding cognitive processes and developing neural-inspired artificial intelligence systems.

  In pursuing this objective, this project not only contributes to the field of computational neuroscience by advancing our knowledge of neural activity patterns associated with decision-making but also demonstrates the potential of machine learning techniques in unraveling the complexities of brain function. As we delve into the analysis and modeling of neural and behavioral data, we stand on the precipice of new discoveries that could further illuminate the neural circuitry underlying decision-making in mammals. (ChatGPT)
  
## Background 

  In this project, we analyze a subset of data collected by Steinmetz et al. (2019). While this document provides the basic understanding of the experiments, it is highly recommended that one consults the original publication for a more comprehensive understanding in order to improve the quality of the analysis report.

  In the study conducted by Steinmetz et al. (2019), experiments were performed on a total of 10 mice over 39 sessions. Each session comprised several hundred trials, during which visual stimuli were randomly presented to the mouse on two screens positioned on both sides of it. The stimuli varied in terms of contrast levels, which took values in {0, 0.25, 0.5, 1}, with 0 indicating the absence of a stimulus. The mice were required to make decisions based on the visual stimuli, using a wheel controlled by their forepaws. A reward or penalty (i.e., feedback) was subsequently administered based on the outcome of their decisions. In particular, 

- When left contrast > right contrast, success (1) if turning the wheel to the right and failure (-1) otherwise.  
- When right contrast > left contrast, success (1) if turning the wheel to the left and failure (-1) otherwise.  
- When both left and right contrasts are zero, success (1) if holding the wheel still and failure (-1) otherwise. 
- When left and right contrasts are equal but non-zero, left or right will be randomly chosen (50%) as the correct choice. 

The activity of the neurons in the mice's visual cortex was recorded during the trials and made available in the form of spike trains, which are collections of timestamps corresponding to neuron firing. In this project, we focus specifically on the spike trains of neurons from the onset of the stimuli to 0.4 seconds post-onset. In addition, we only use 18 sessions (Sessions 1 to 18) from four mice: Cori, Frossman, Hence, and Lederberg.

## Data Structure 

  To understand the data's structure, we are going to randomly explore one of the 18 sessions. 
  
  Starting the EDA with a single session before moving to the entire dataset is a strategic decision that helps in understanding the data better, refining your analysis techniques, ensuring computational efficiency, and establishing a baseline for further comparative analyses. This approach not only enhances the quality of the data analysis but also contributes to a more coherent and comprehensive understanding of the data as a whole. (ChatGPT)
  
  A total of 18 RDS files are provided that contain the records from 18 sessions. In each RDS file, you can find the name of mouse from `mouse_name` and date of the experiment from `date_exp`. 

There are a total of 18 RDS files provided that contain the records from 18 sessions. Each file contains the name of mouse from `mouse_name` and date of the experiment from `date_exp`. 

*From ChatGPT, we then create a consolidated data frame that includes session number, mouse name, and date of experiment for each session, as a RDS file overview:
```{r echo=FALSE}
# Load necessary libraries
library(dplyr)

# Initialize an empty data frame to store session info
session_info <- data.frame(session_number = integer(),
                           mouse_name = character(),
                           date_exp = character(),
                           stringsAsFactors = FALSE) # To keep character strings

# Loop through each session, read RDS file, and extract info
for(i in 1:18){
  # Construct the file path
  file_path <- paste0('./Data/session', i, '.rds')
  
  # Load the RDS file
  session_data <- readRDS(file_path)
  
  # Extract mouse name and date of experiment
  mouse_name <- session_data$mouse_name
  date_exp <- session_data$date_exp
  
  # Append the information to the session_info data frame
  session_info <- rbind(session_info, data.frame(session_number = i,
                                                  mouse_name = mouse_name,
                                                  date_exp = date_exp,
                                                  stringsAsFactors = FALSE))
}

# View the consolidated data frame
print(session_info)
```
From the dataset, we can see that there are 18 sessions, where Sessions 1-3 have the mouse_name = Cori, Sessions 4-7 have mouse_name Forssmann, Sessions 8-11 have the mouse_name Hench, and Sessions 13-18 have mouse_name Lederberg, respectively.

We then, now, explore what's in a session by randomly exploring a session from Session 1-18, before we explore the rest of the 18 sessions. 


## What's in a session?  
```{r}
# Code provided
session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('./Data/session',i,'.rds',sep=''))
  #print(session[[i]]$mouse_name)
  #print(session[[i]]$date_exp)
}

# Prints out variables in Session 1
#names(session[[1]])

# Prints out variables in Session 18
#names(session[[18]])

# Prints out variables in Session 13
#names(session[[13]])


#names(session[[1]])

summary(session[[1]]$brain_area)

#table(session[[1]]$brain_area)

```

```{r}
# Behavioural data

summary(session[[1]]$contrast_left) # Summary statistics of 
#table(session[[1]]$contrast_left) #  frequency of trials that were conducted with each specific level of left stimulus contrast in Session 1.
#length(session[[1]]$contrast_left) # total number of trials for contrast_left in Session 1

#table(session[[1]]$contrast_right)
#length(session[[1]]$contrast_right)


#summary(session[[1]]$feedback_type)
#table(session[[1]]$feedback_type)
```

```{r}
# Neural data

typeof(session[[1]]$spks)

length(session[[1]]$spks)

dim(session[[1]]$spks[[10]]) # the number of neurons (734) by the number of time bins (40)

length(session[[1]]$spks[[10]][5,])


typeof(session[[1]]$time)
session[[1]]$time[[10]]

session[[1]]$feedback_type[10]


session[[1]]$contrast_left[10]

session[[1]]$contrast_right[10]


# session[[1]]$spks[[10]] ----  session[[1]]$feedback_type[10]
```

Five variables are available for each trial, namely 

- `feedback_type`: type of the feedback, 1 for success and -1 for failure
- `contrast_left`: contrast of the left stimulus
- `contrast_right`: contrast of the right stimulus
- `time`: centers of the time bins for `spks`  
- `spks`: numbers of spikes of neurons in the visual cortex in time bins defined in `time`
- `brain_area`: area of the brain where each neuron lives

## What's in a trial?
```{r}
# Assuming 'sessions' is a list of sessions
# Each session contains trials and other information as described

# Initialize a vector to store the number of trials in each session
number_of_trials_per_session <- integer(length(session))

# Loop through each session to count the trials
for (i in seq_along(session)) {
  # Count the number of trials in the ith session
  # Assuming trials are stored in a list or a similar structure
  number_of_trials_per_session[i] <- length(session[[i]]$spks)
}

# Print the number of trials in each session
print(number_of_trials_per_session)

library(dplyr)

# Initialize an empty data frame to store session info and trial counts
session_info_trials <- data.frame(session_number = integer(),
                                  mouse_name = character(),
                                  trial_count = integer(),
                                  stringsAsFactors = FALSE) # To keep character strings

# Loop through each session, read RDS file, extract info, and count trials
for(i in 1:18){
  # Construct the file path
  file_path <- paste0('./Data/session', i, '.rds')
  
  # Load the RDS file
  session_data <- readRDS(file_path)
  
  # Extract mouse name and date of experiment
  mouse_name <- session_data$mouse_name
  
  # Count the number of trials in the session
  trial_count <- length(session_data$spks)
  
  # Append the information to the session_info_trials data frame
  session_info_trials <- rbind(session_info_trials, data.frame(session_number = i,
                                                                mouse_name = mouse_name,
                                                                trial_count = trial_count,
                                                                stringsAsFactors = FALSE))
}

# View the consolidated data frame with trial counts
print(session_info_trials)


dim(session[[1]]$spks[[1]]) 
length(session[[1]]$brain_area)
session[[1]]$spks[[1]][6,] # Each row contains 40 time bins. 
```

## How to connect the neuron spike with brain region?
```{r}
session[[1]]$spks[[1]][6,3] 
session[[1]]$brain_area[6]
```

The above information tells us in session 1 trail 1, the 6 neuron (from area ACA) has a spike at time bin 3. 

# Data processing 

I denote the ``spike rate`` per neuron as the sum of spikes over the 40 time bins. 
The ``region_mean_spike`` records the average of spike rate over each region. 

```{r}
get_trail_data <- function(session_id, trail_id){
  spikes <- session[[session_id]]$spks[[trail_id]]
  if (any(is.na(spikes))){
    disp("value missing")
  }

  #trail_tibble <- as_tibble(spikes) %>% set_names(binename) %>%  add_column("brain_area" = session[[session_id]]$brain_area ) %>% group_by(brain_area) %>% summarize( "sum_spikes" =across(everything(),sum),.groups = "drop") 
  trail_tibble <- tibble("neuron_spike" = rowSums(spikes))  %>%  add_column("brain_area" = session[[session_id]]$brain_area ) %>% group_by(brain_area) %>% summarize( region_sum_spike = sum(neuron_spike), region_count = n(),region_mean_spike = mean(neuron_spike)) 
  trail_tibble  = trail_tibble%>% add_column("trail_id" = trail_id) %>% add_column("contrast_left"= session[[session_id]]$contrast_left[trail_id]) %>% add_column("contrast_right"= session[[session_id]]$contrast_right[trail_id]) %>% add_column("feedback_type"= session[[session_id]]$feedback_type[trail_id])
  trail_tibble
}

```



```{r}
trail_tibble_1_2 <- get_trail_data(1,2)
trail_tibble_1_2
```
```{r,echo=FALSE}

get_session_data <- function(session_id){
  n_trail <- length(session[[session_id]]$spks)
  trail_list <- list()
  for (trail_id in 1:n_trail){
    trail_tibble <- get_trail_data(session_id,trail_id)
    trail_list[[trail_id]] <- trail_tibble
  }
  session_tibble <- do.call(rbind, trail_list)
  session_tibble <- session_tibble %>% add_column("mouse_name" = session[[session_id]]$mouse_name) %>% add_column("date_exp" = session[[session_id]]$date_exp) %>% add_column("session_id" = session_id) 
  session_tibble
}

```

```{r}
session_1 <- get_session_data(1)
head(session_1)
```

```{r,echo=FALSE}
session_list = list()
for (session_id in 1: 18){
  session_list[[session_id]] <- get_session_data(session_id)
}
full_tibble <- do.call(rbind, session_list)
full_tibble$success <- full_tibble$feedback_type == 1
full_tibble$success <- as.numeric(full_tibble$success)
full_tibble$contrast_diff <- abs(full_tibble$contrast_left-full_tibble$contrast_right)

```

Here is another way of data processing. For each trail, I take the average of neuron spikes over each time bin. I denote it as ``trail_bin_average``

```{r,echo=FALSE}
binename <- paste0("bin", as.character(1:40))

get_trail_functional_data <- function(session_id, trail_id){
  spikes <- session[[session_id]]$spks[[trail_id]]
  if (any(is.na(spikes))){
    disp("value missing")
  }

  trail_bin_average <- matrix(colMeans(spikes), nrow = 1)
  colnames(trail_bin_average) <- binename
  trail_tibble  = as_tibble(trail_bin_average)%>% add_column("trail_id" = trail_id) %>% add_column("contrast_left"= session[[session_id]]$contrast_left[trail_id]) %>% add_column("contrast_right"= session[[session_id]]$contrast_right[trail_id]) %>% add_column("feedback_type"= session[[session_id]]$feedback_type[trail_id])
  
  trail_tibble
}
get_session_functional_data <- function(session_id){
  n_trail <- length(session[[session_id]]$spks)
  trail_list <- list()
  for (trail_id in 1:n_trail){
    trail_tibble <- get_trail_functional_data(session_id,trail_id)
    trail_list[[trail_id]] <- trail_tibble
  }
  session_tibble <- as_tibble(do.call(rbind, trail_list))
  session_tibble <- session_tibble %>% add_column("mouse_name" = session[[session_id]]$mouse_name) %>% add_column("date_exp" = session[[session_id]]$date_exp) %>% add_column("session_id" = session_id) 
  session_tibble
}

```
```{r, echo = FALSE}
session_list = list()
for (session_id in 1: 18){
  session_list[[session_id]] <- get_session_functional_data(session_id)
}
full_functional_tibble <- as_tibble(do.call(rbind, session_list))
full_functional_tibble$session_id <- as.factor(full_functional_tibble$session_id )
full_functional_tibble$contrast_diff <- abs(full_functional_tibble$contrast_left-full_functional_tibble$contrast_right)

full_functional_tibble$success <- full_functional_tibble$feedback_type == 1
full_functional_tibble$success <- as.numeric(full_functional_tibble$success)
```

In the following table, each row contains information of a particular trail. The columns contains the average spike rate for each time bin.

```{r,echo=FALSE}
head(full_functional_tibble)
```

# Section 2 Exploratory Data Analysis (20 pts).

**Goal of EDA**: 

0. Final task is to predict the results of random trails from session 1 and session 18. 

1. What are some interesting patterns of the data, especially the similarity and difference among different observations (trails). This will answer the question of how to select our training samples. 
2. What patterns make a trail more likely to have a successful response. This will answer the question of how to build our training features.

## What is different for each session/mouse
### What are the number of neuron's in each session?
```{r, echo=FALSE}
full_tibble %>% filter (trail_id==1) %>% group_by(session_id) %>% summarise(sum(region_count))
```
### What is the number brain area of each session
```{r, echo=FALSE}
full_tibble %>% group_by(session_id) %>% summarise(unique_area = n_distinct(brain_area))
```

### What is the average spike rate over each session 

The average spike rate is the total number of spikes divided by the total number of time bins for each session
```{r, echo=FALSE}
average_spike <-full_tibble %>% group_by( session_id, trail_id) %>% mutate(mean_spike = sum(region_sum_spike)/sum(region_count))
average_spike %>% group_by(session_id) %>% summarise(mean_session_spike = mean(mean_spike))
```

### What are the brain areas with neurons recorded in each session?

```{r,echo=FALSE}
ggplot(full_tibble, aes(x =session_id , y = brain_area)) +
  geom_point() +
  labs(x = "session_id" , y ="brain_area") +
  scale_x_continuous(breaks = unique(full_tibble$session_id)) +  
  theme_minimal()
```

### Estimate success rate over different groups (session and mouse)

```{r,echo=FALSE}
full_functional_tibble %>% group_by(session_id) %>% summarize(success_rate = mean(success, na.rm = TRUE))
```
```{r,echo=FALSE}
full_functional_tibble %>% group_by(mouse_name) %>% summarize(success_rate = mean(success, na.rm = TRUE))
```


## What is different among each trail?

### What is the contrast difference distribution?
```{r,echo=FALSE}
full_functional_tibble %>% group_by(contrast_diff) %>% count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc))
```

### How does the contrast difference affect the success rate?
```{r,echo=FALSE}
full_functional_tibble %>% group_by(contrast_diff) %>% summarize(success_rate = mean(success, na.rm = TRUE))
```

### Does the success rate difference among mice cause the different distributions of contrast difference? 

```{r,echo=FALSE}
counts_df <- full_functional_tibble[c('mouse_name', 'contrast_diff')]
counts_df$contrast_diff <- as.factor(counts_df$contrast_diff)
counts <- table(counts_df)

percentages <- prop.table(counts, margin = 1)
percentages

```

Can you use two-way ANOVA to answer the above question more rigorously? 




### Visualize success rate change over time (trail)
The success rate is binned for each 25 trails.
```{r,echo=FALSE}
full_functional_tibble$trail_group = cut(full_functional_tibble$trail_id, breaks = seq(0, max(full_functional_tibble$trail_id), by = 25),include.lowest = TRUE)
levels(full_functional_tibble$trail_group) <- seq(0, max(full_functional_tibble$trail_id), by = 25)[2:18]
```

The success rate change over time for individual sessions:

```{r,echo=FALSE}
success_rate <- aggregate(success ~ session_id + trail_group, data = full_functional_tibble, FUN = function(x) mean(x) )
ggplot(success_rate, aes(x = trail_group, y = success)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~session_id, ncol=3) +
      theme_bw()

```

The success rate change over time for individual mouse:

```{r,echo=FALSE}
success_rate <- aggregate(success ~ mouse_name + trail_group, data = full_functional_tibble, FUN = function(x) mean(x) )
ggplot(success_rate, aes(x = trail_group, y = success)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~mouse_name) +
      theme_bw()
```


### Visualize the change of overall neuron spike rate over time

The ``average_spike`` is the number of spikes within each number bin divided total number of neurons for each trail.

```{r,echo=FALSE}
col_names <-names(full_functional_tibble)
region_sum_subset <- col_names[grep("^region_sum", col_names)]
region_mean_subset <- col_names[grep("^region_mean", col_names)]

```
```{r,echo=FALSE}
# average_spike <- full_tibble %>% group_by( session_id,trail_id) %>% summarise(mean_spike = mean(region_mean_spike))
average_spike <- full_tibble %>% group_by( session_id,trail_id) %>% summarise(mean_spike = sum(region_sum_spike)/sum(region_count))

average_spike$mouse_name <- full_functional_tibble$mouse_name
average_spike$contrast_diff <- full_functional_tibble$contrast_diff
average_spike$success <- full_functional_tibble$success
```

The change of overall neuron spike rate for each session 

```{r,echo=FALSE}
ggplot(average_spike, aes(x = trail_id, y = mean_spike)) + 
  geom_line()+
  geom_smooth(method = "loess")+  # Fit a smooth spline

  facet_wrap(~session_id)
```

The change of overall neuron spike rate for each mouse 

```{r,echo=FALSE}
ggplot(average_spike, aes(x = trail_id, y = mean_spike)) + 
  geom_line()+
  geom_smooth(method = "loess")+  # Fit a smooth spline

  facet_wrap(~mouse_name)
```

# Dimension Reduction through PCA


We perform PCA and visualize the 2D results. 

```{r, echo = FALSE}
features = full_functional_tibble[,1:40]
scaled_features <- scale(features)
pca_result <- prcomp(scaled_features)
pc_df <- as.data.frame(pca_result$x)
pc_df$session_id <- full_functional_tibble$session_id
pc_df$mouse_name <- full_functional_tibble$mouse_name
```

The dots are colored for different session. 

```{r, echo = FALSE}
ggplot(pc_df, aes(x = PC1, y = PC2, color = session_id)) +
  geom_point() +
  labs(title = "PCA: PC1 vs PC2")
```

The dots are colored for different mouse 
```{r, echo = FALSE}
ggplot(pc_df, aes(x = PC1, y = PC2, color = mouse_name)) +
  geom_point() +
  labs(title = "PCA: PC1 vs PC2")
```

What can be found through these two plots? 



# Section 3 Data integration (20 pts).

I decide to use trails from all sessions first and see the performance. The feature I decide to use are session_id, trail_id, signals, and the average spike rate of each time bin.


```{r}
predictive_feature <- c("session_id","trail_id","contrast_right","contrast_left", "contrast_diff" ,binename)
head(full_functional_tibble[predictive_feature])
```
```{r,echo=FALSE}
predictive_dat <- full_functional_tibble[predictive_feature]
#predictive_dat$success <- as.numeric(predictive_dat$success)
predictive_dat$trail_id <- as.numeric(predictive_dat$trail_id)
label <- as.numeric(full_functional_tibble$success)
X <- model.matrix(~., predictive_dat)

```

# Section 4 Predictive modeling (20 pts).


# Prediction
## train the model on 80% trails and test it on the rest 

```{r}
# split
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(label, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_df <- predictive_dat[trainIndex, ]
train_X <- X[trainIndex,]
test_df <- predictive_dat[-trainIndex, ]
test_X <- X[-trainIndex,]

train_label <- label[trainIndex]
test_label <- label[-trainIndex]
```

I decide to go with xgboost because I have lots of features, I expect there are some interactions among those interactions, and I have a relative large training set to avoid overfitting. 

```{r}

xgb_model <- xgboost(data = train_X, label = train_label, objective = "binary:logistic", nrounds=10)

```

Prediction results (accuracy, confusion matrix, AUROC)
```{r}
predictions <- predict(xgb_model, newdata = test_X)
predicted_labels <- as.numeric(ifelse(predictions > 0.5, 1, 0))
accuracy <- mean(predicted_labels == test_label)
accuracy

```
```{r}
conf_matrix <- confusionMatrix(as.factor(predicted_labels), as.factor(test_label))
conf_matrix$table

```
```{r}
auroc <- roc(test_label, predictions)
auroc
```

# Section 5 Prediction performance on the test sets (5 pts).


## test the model's performance on 50 random trails from session 18
```{r}
# split
set.seed(123) # for reproducibility
session_18_row <- which(full_functional_tibble$session_id==18)
testIndex <- sample(session_18_row, 50, replace = FALSE)
trainIndex <- 1:nrow(full_functional_tibble)
trainIndex <- trainIndex[!(trainIndex %in% testIndex)]

train_df <- predictive_dat[trainIndex, ]
train_X <- X[trainIndex,]
test_df <- predictive_dat[-trainIndex, ]
test_X <- X[-trainIndex,]

train_label <- label[trainIndex]
test_label <- label[-trainIndex]
```

Prediction results (accuracy, confusion matrix, AUROC)

```{r}
xgb_model <- xgboost(data = train_X, label = train_label, objective = "binary:logistic", nrounds=10)
predictions <- predict(xgb_model, newdata = test_X)
predicted_labels <- as.numeric(ifelse(predictions > 0.5, 1, 0))
accuracy <- mean(predicted_labels == test_label)
accuracy
conf_matrix <- confusionMatrix(as.factor(predicted_labels), as.factor(test_label))
conf_matrix$table
auroc <- roc(test_label, predictions)
auroc
```

## test the model's performance on 50 random trails from session 1
```{r,echo=FALSE}
# split
set.seed(123) # for reproducibility
session_1_row <- which(full_functional_tibble$session_id==1)
testIndex <- sample(session_1_row, 50, replace = FALSE)
trainIndex <- 1:nrow(full_functional_tibble)
trainIndex <- trainIndex[!(trainIndex %in% testIndex)]

train_df <- predictive_dat[trainIndex, ]
train_X <- X[trainIndex,]
test_df <- predictive_dat[-trainIndex, ]
test_X <- X[-trainIndex,]

train_label <- label[trainIndex]
test_label <- label[-trainIndex]
```

Prediction results (accuracy, confusion matrix, AUROC)

```{r,echo=FALSE}
xgb_model <- xgboost(data = train_X, label = train_label, objective = "binary:logistic", nrounds=10)
predictions <- predict(xgb_model, newdata = test_X)
predicted_labels <- as.numeric(ifelse(predictions > 0.5, 1, 0))
accuracy <- mean(predicted_labels == test_label)
accuracy
conf_matrix <- confusionMatrix(as.factor(predicted_labels), as.factor(test_label))
conf_matrix$table
auroc <- roc(test_label, predictions)
auroc
```

# Section 6 Discussion (5 pts).

 [ADD DISCUSSION HERE]
 
# Reference {-}

Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x