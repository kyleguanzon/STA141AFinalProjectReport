---
title: "Neural Activity and Behavioral Predictions: An Analysis of Behavioral Outcomes in Mice"
author: "Kyle Guanzon"
date: "2024-03-17"
output: 
  html_document:
    theme: yeti
    toc: true
    toc_float: true

---
```{r include=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(tidyverse)
library(caret) 
library(xgboost)
library(pROC) # To create citations
```

# Abstract

  Neural activity and behavioral outcomes are examines to illustrate the complexities of decision-making in mammal species. This study leverages the comprehensive neural spike train data from the groundbreaking research by Steinmetz et al. (2019), focusing on the visual cortex's response to stimuli in mice. This report bridges the gap between observed neural activity and the predictive modeling of behavioral outcomes. Undergoing thorough exploratory data analysis methods, key patterns and relationships within spike trains are identified, in relation to the success and failure of behavioral responses to visual stimuli. Machine learning algorithms such as XGBoost is implemented to train the model created, which is further evaluated by AUROC. Resources and code were obtained from STA 141A discussions and course notes, as well as ChatGPT. 

# Section 1: Introduction

  In the study conducted by Steinmetz et al. (2019), experiments were performed on a total of 10 mice over 39 sessions. Each session comprised several hundred trials, during which visual stimuli were randomly presented to the mouse on two screens positioned on both sides of it. The stimuli varied in terms of contrast levels, which took values in {0, 0.25, 0.5, 1}, with 0 indicating the absence of a stimulus. The mice were required to make decisions based on the visual stimuli, using a wheel controlled by their forepaws. A reward or penalty (i.e., feedback) was subsequently administered based on the outcome of their decisions. In particular, 

- When left contrast > right contrast, success (1) if turning the wheel to the right and failure (-1) otherwise.  
- When right contrast > left contrast, success (1) if turning the wheel to the left and failure (-1) otherwise.  
- When both left and right contrasts are zero, success (1) if holding the wheel still and failure (-1) otherwise. 
- When left and right contrasts are equal but non-zero, left or right will be randomly chosen (50%) as the correct choice. 

The activity of the neurons in the mice's visual cortex was recorded during the trials and made available in the form of spike trains, which are collections of timestamps corresponding to neuron firing. In this project, we focus specifically on the spike trains of neurons from the onset of the stimuli to 0.4 seconds post-onset. In addition, we only use 18 sessions (Sessions 1 to 18) from four mice: Cori, Frossman, Hence, and Lederberg.

This study aims to identify patterns and relationships that can help us understand the neural basis of decision-making by concentrating on the finely tuned spike trains of neurons in the mice's visual cortex and the circumstances of the visual stimuli presented. This project aims to improve our predictive capabilities by combining exploratory data analysis data integration strategies and predictive modeling. The insights it provides could have a wide range of implications for neuroscience especially in terms of comprehending cognitive processes and creating artificial intelligence systems inspired by neurons.

This project not only advances our understanding of neural activity patterns linked to decision-making which benefits the field of computational neuroscience but it also shows how machine learning techniques can be used to decipher the intricate workings of the human brain. We are at the cusp of making new discoveries in the analysis and modeling of neural and behavioral data that may shed more light on the neural circuitry underlying decision-making in mammals.

## Data Structure 
  
  A total of 18 RDS files are provided that contain the records from 18 sessions. The name of mouse from `mouse_name` and date of the experiment from `date_exp` in each RDS file. 
  
  There are a total of 18 RDS files provided that contain the records from 18 sessions. Each file contains the name of mouse from `mouse_name` and date of the experiment from `date_exp`. 
 
 From the research paper, we also know that there are $x$ trials in a given session. We will use this information to determine the total number of trials per session.
 
 We then create a consolidated data frame that includes session number, mouse name, and date of experiment for each session, as a RDS file overview:
```{r echo=FALSE}
#From ChatGPT
# Code provided
session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('./Data/session',i,'.rds',sep=''))
}

# From ChatGPT
# Initialize a vector to store the number of trials in each session
number_of_trials_per_session <- integer(length(session))

# Loop through each session to count the trials
for (i in seq_along(session)) {
  # Count the number of trials in the ith session
  # Assuming trials are stored in a list or a similar structure
  number_of_trials_per_session[i] <- length(session[[i]]$spks)
}

# Initialize an empty data frame to store session info
session_info <- data.frame(session_number = integer(),
                           mouse_name = character(),
                           tial_count = integer(),
                           date_exp = character(),
                           stringsAsFactors = FALSE) # To keep character strings

# Loop through each session, read RDS file, and extract info
for(i in 1:18){
  # Construct the file path
  file_path <- paste0('./Data/session', i, '.rds')
  
  # Load the RDS file
  session_data <- readRDS(file_path)
  
  # Extract mouse name and date of experiment
  mouse_name <- session_data$mouse_name
  date_exp <- session_data$date_exp
  
  # Count the number of trials in the session
  trial_count <- length(session_data$spks)
  
  # Append the information to the session_info data frame
  session_info <- rbind(session_info, data.frame(session_number = i,
                                                  mouse_name = mouse_name,
                                                  date_exp = date_exp,
                                                  trial_count = trial_count,
                                                  stringsAsFactors = FALSE))
}

# View the consolidated data frame
print(session_info)
```
  From the dataset, we can see that there are 18 sessions, where Sessions 1-3 have the `mouse_name` = Cori, Sessions 4-7 have `mouse_name` Forssmann, Sessions 8-11 have the `mouse_name` Hench, and Sessions 13-18 have `mouse_name` Lederberg, respectively.

  We then, now, explore what's in a session by randomly exploring a session from Session 1-18, before we explore the rest of the 18 sessions. 
  
  Its a wise strategic move to begin the EDA with a single session before working your way through the entire dataset. This will help better understand the data hone your analysis methods guarantee computational efficiency and create a baseline for additional comparative analyses. By using this method the data analysis becomes more high-quality and the overall understanding of the data becomes more comprehensive and logical. 

### What's in a Session's Trial?

We randomly choose Session 12 to understand the data structure. 

```{r include=FALSE}
names(session[[12]]) # Prints out variables present in Session 12
```


```{r echo=FALSE}
summary(session[[12]]) # Prints out variables in Session 12 and its total length for each variable
```
Five variables are available for each trial, namely 

- `feedback_type`: type of the feedback, 1 for success and -1 for failure
- `contrast_left`: contrast of the left stimulus
- `contrast_right`: contrast of the right stimulus
- `time`: centers of the time bins for `spks`  
- `spks`: numbers of spikes of neurons in the visual cortex in time bins defined in `time`
- `brain_area`: area of the brain where each neuron lives

### Neural Data 

We browse through Neural Data by exploring the variables brain_area and spks of Session 12. 
```{r echo=FALSE}
summary(session[[12]]$brain_area) #summary() usually returns a frequency count of the different categories or levels present in the column.
```
There are a total of `r length(session[[12]]$brain_area)` neurons in Session 12. Each entry corresponds to a neuron, indicating the brain area where that neuron is located. We also obtain the total number of trials from the `length()` of spks, which is `r length(session[[12]]$spks)`.

The distribution of neurons with their corresponding brain areas is illustrated below:
```{r echo=FALSE}
table(session[[12]]$brain_area) 
```
This means that of all `r length(session[[12]]$spks)` trials in Session 12, the `r length(session[[12]]$brain_area)` neurons are distributed with their corresponding brain areas.

```{r include=FALSE}
#We then, further look at Session 12, Trial 1. Using the code, `dim(session[[12]]$spks[[1]])`, we obtain the dimension result:
dim(session[[12]]$spks[[1]])
#From the result, we can see that 698 neurons were recorded over 40 time bins in Session 12.

session[[12]]$spks[[1]][6,] # Each row contains 40 time bins. 

# We connect the neuron spike with brain region
session[[12]]$spks[[1]][6,] 

session[[12]]$brain_area[6]

# The above information tells us in session 12 trial 1, the 6 neuron (from area VISp) does not have a spike at time bin 6. 
```

```{r include=FALSE}
# Neural data
length(session[[12]]$spks)

dim(session[[12]]$spks[[10]]) # the number of neurons (734) by the number of time bins (40) in session 12, trial # 10

length(session[[12]]$spks[[10]][5,])


typeof(session[[12]]$time)
session[[12]]$time[[10]]

session[[12]]$feedback_type[10]


session[[12]]$contrast_left[10]

session[[12]]$contrast_right[10]

# session[[1]]$spks[[10]] ----  session[[1]]$feedback_type[10]
```

### Behavioral Data 

We browse through Behavioral Data by exploring the variables `contrast_left`, `contrast_right`, and `feedback_type` of Session 12. 

The stimuli varied in terms of contrast levels, which took values in {0, 0.25, 0.5, 1}, with 0 indicating the absence of a stimulus.

```{r include=FALSE}
# Behavioural data
summary(session[[12]]$contrast_left) # Summary statistics of Session 12's contrast_left
```

Taking the summary statistics of `contrast_left` of Session 12, we can see that the average stimulus provided to the mouse is `r mean(session[[12]]$contrast_left)`, the highest stimulus is `r max(session[[12]]$contrast_left)`, whereas the lowest stimulus value given is `r min(session[[12]]$contrast_left)`.

The distribution of the four stimulus levels in left contrast is provided below, which sums up to the total number of trials in `contrast_left` for Session 12, which is `r length(session[[12]]$contrast_left)`.

```{r echo=FALSE}
table(session[[12]]$contrast_left) #  frequency of trials that were conducted with each specific level of left stimulus contrast in Session 1.
```

We also explore similarly for `contrast_right`:

```{r include=FALSE}
summary(session[[12]]$contrast_right)
```
Taking the summary statistics of contrast_right of Session 12, we can see that the average stimulus provided to the mouse is `r mean(session[[12]]$contrast_right)`, the highest stimulus is `r max(session[[12]]$contrast_right)`, whereas the lowest stimulus value given is `r min(session[[12]]$contrast_right)`.

The distribution of the four stimulus levels in left contrast is provided below, which sums up to the total number of trials in `contrast_right` for Session 12, which is `r length(session[[12]]$contrast_right)`.

```{r echo=TRUE}
table(session[[12]]$contrast_right)
```

Subsequently, we explore the success and failures of Session 1 trials through the variable `feedback_type`.
```{r include=FALSE}
summary(session[[12]]$feedback_type)
```

Taking the summary statistics of `feedback_type` of Session 12, we can see that the average stimulus provided to the mouse is `r mean(session[[12]]$feedback_type)`, the highest stimulus is `r max(session[[12]]$feedback_type)`, whereas the lowest stimulus value given is `r min(session[[12]]$feedback_type)`.

The distribution two feedback levels in Session 12 is provided below, which sums up to the total number of trials in for Session 12, which is `r length(session[[12]]$feedback_type)`.
```{r echo=FALSE}
table(session[[12]]$feedback_type)
```

## Data Processing

Going over the data structure of Session 12, we now are equipped to transform and integrate the data into a more meaningful outcome. 

```{r include=FALSE}
#I denote the ``spike rate`` per neuron as the sum of spikes over the 40 time bins. 
#The ``region_mean_spike`` records the average of spike rate over each region. 

#trial ID is trial number
get_trial_data <- function(session_id, trial_id){
  spikes <- session[[session_id]]$spks[[trial_id]]
  if (any(is.na(spikes))){
    disp("value missing")
  }

  #trial_tibble <- as_tibble(spikes) %>% set_names(binename) %>%  add_column("brain_area" = session[[session_id]]$brain_area ) %>% group_by(brain_area) %>% summarize( "sum_spikes" =across(everything(),sum),.groups = "drop") 
  
  trial_tibble <- tibble("neuron_spike" = rowSums(spikes, na.rm=TRUE))  %>%
    add_column("brain_area" = session[[session_id]]$brain_area ) %>% 
    group_by(brain_area) %>% 
    summarize( region_sum_spike = sum(neuron_spike), 
               region_count = n(),
               region_mean_spike = mean(neuron_spike)) 
  
  trial_tibble  = trial_tibble %>% 
    add_column("trial_id" = trial_id) %>% 
    add_column("contrast_left"= session[[session_id]]$contrast_left[trial_id]) %>%
    add_column("contrast_right"= session[[session_id]]$contrast_right[trial_id]) %>%
    add_column("feedback_type"= session[[session_id]]$feedback_type[trial_id])
  trial_tibble
}
```

We create a tibble that obtains the trial data of a session. In this case, we obtain the first trial data of Session 12:

```{r echo=FALSE}
trial_tibble_1_2 <- get_trial_data(12,1)
trial_tibble_1_2
```
We also create a tibble that obtains data of a session itself. We obtain the data of Session 12:
```{r include=FALSE}
get_session_data <- function(session_id){
  n_trial <- length(session[[session_id]]$spks)
  trial_list <- list()
  for (trial_id in 1:n_trial){
    trial_tibble <- get_trial_data(session_id,trial_id)
    trial_list[[trial_id]] <- trial_tibble
  }
  session_tibble <- do.call(rbind, trial_list)
  session_tibble <- session_tibble %>% add_column("mouse_name" = session[[session_id]]$mouse_name) %>% add_column("date_exp" = session[[session_id]]$date_exp) %>% add_column("session_id" = session_id) 
  session_tibble
}
```

```{r echo=FALSE}
session_12 <- get_session_data(12)
head(session_12)
```
To compare the two tibbles, we can see that the values for `region_sum_spike`, `region_count`, and `region_mean_spike` are the same. We may conclude that the number of neurons for each session's trial is constant, or the same for all trials in one session. 

```{r,include=FALSE}
session_list = list()
for (session_id in 1: 18){
  session_list[[session_id]] <- get_session_data(session_id)
}
full_tibble <- do.call(rbind, session_list)
full_tibble$success <- full_tibble$feedback_type == 1
full_tibble$success <- as.numeric(full_tibble$success)
full_tibble$contrast_diff <- abs(full_tibble$contrast_left-full_tibble$contrast_right)

```


```{r,include=FALSE}
#We also do an alternative way of data processing. For each trial, the average of neuron spikes over each time bin is taken. I denote it as ``trial_bin_average``

binename <- paste0("bin", as.character(1:40))

get_trial_functional_data <- function(session_id, trial_id){
  spikes <- session[[session_id]]$spks[[trial_id]]
  if (any(is.na(spikes))){
    disp("value missing")
  }

  trial_bin_average <- matrix(colMeans(spikes), nrow = 1)
  colnames(trial_bin_average) <- binename
  trial_tibble  = as_tibble(trial_bin_average)%>% add_column("trial_id" = trial_id) %>% add_column("contrast_left"= session[[session_id]]$contrast_left[trial_id]) %>% add_column("contrast_right"= session[[session_id]]$contrast_right[trial_id]) %>% add_column("feedback_type"= session[[session_id]]$feedback_type[trial_id])
  
  trial_tibble
}
get_session_functional_data <- function(session_id){
  n_trial <- length(session[[session_id]]$spks)
  trial_list <- list()
  for (trial_id in 1:n_trial){
    trial_tibble <- get_trial_functional_data(session_id,trial_id)
    trial_list[[trial_id]] <- trial_tibble
  }
  session_tibble <- as_tibble(do.call(rbind, trial_list))
  session_tibble <- session_tibble %>% add_column("mouse_name" = session[[session_id]]$mouse_name) %>% add_column("date_exp" = session[[session_id]]$date_exp) %>% add_column("session_id" = session_id) 
  session_tibble
}
```

```{r, include=FALSE}
session_list = list()
for (session_id in 1: 18){
  session_list[[session_id]] <- get_session_functional_data(session_id)
}
full_functional_tibble <- as_tibble(do.call(rbind, session_list))
full_functional_tibble$session_id <- as.factor(full_functional_tibble$session_id )
full_functional_tibble$contrast_diff <- abs(full_functional_tibble$contrast_left-full_functional_tibble$contrast_right)

full_functional_tibble$success <- full_functional_tibble$feedback_type == 1
full_functional_tibble$success <- as.numeric(full_functional_tibble$success)
```

```{r,include=FALSE}
#In the following table, each row contains information of a particular trial. The columns contains the average spike rate for each time bin.
head(full_functional_tibble)
```

# Section 2: Exploratory Data Analysis

The goal of the Exploratory Data Analysis is to provide a strong basis for precisely projecting the results of random trials conducted between sessions 1 and 18. The objective is to reveal intriguing patterns by thoroughly examining the dataset with a particular emphasis on highlighting the commonalities and discrepancies among different observations or trials. Finding the best way to choose our training samples is essential to making sure the predictive model is trained on representative and instructive data. This can be achieved through thorough investigation. 

Furthermore, a large portion of the investigation is devoted to pinpointing particular patterns that signify the success of a trial. We can build reliable training features that predict trial outcomes by using an understanding of these patterns as a guide. 

The EDA not only sets the stage for more complex predictive modeling, but it also improves the comprehension of the underlying dynamics affecting trial outcomes which helps to shape the creation of predictive models that are more precise and trustworthy.

### Total Neurons Per Session

(Each trial has the same amount of neurons for each session)
```{r, echo=FALSE}
full_tibble %>%
  filter (trial_id==1) %>%
  group_by(session_id) %>%
  summarise(sum(region_count))
```
We can see that Sessions 4, 10, 6, 8, and 18 have the top 5 highest `region_counts`. We may assume that there is higher neuron activity in these Sessions. Those with lower `region_counts`, such as Sessions 16, 7, 17, 3, and 12, have lower neuron activity, respectively. 

```{r echo=FALSE}
# Brain areas activated in each session:
full_tibble %>% 
  group_by(session_id) %>% 
  summarise(unique_area = n_distinct(brain_area))
```

### Average Spike Rate Over Each Session

The average spike rate is the total number of spikes divided by the total number of time bins for each session.
```{r, echo=FALSE}
average_spike <-full_tibble %>% 
  group_by( session_id, trial_id) %>% 
  mutate(mean_spike = sum(region_sum_spike)/sum(region_count))

average_spike %>% 
  group_by(session_id) %>% 
  summarise(mean_session_spike = mean(mean_spike))
```
From the tibble, we observe that the top 3 highest mean spikes belong in Sessions 13, 3, and 12. We may derive from this observation that there presents greater spike activity in these Sessions. 

### Visualization of Brain Area Activity Per Session

We provide a visualization of brain areas activated in each Session. Sessions 8 and 13 are tied for the greatest number of brain areas, which is 13. In reference to the tibbles highlighting the total neuron count and average spike rate over each session, we may add to the conclusion that Sessions 8 and 13 may have greater spike and neuron activity. 

```{r,echo=FALSE}
ggplot(full_tibble, aes(x =session_id , y = brain_area)) +
  geom_point() +
  labs(x = "session_id" , y ="brain_area", title = "Brain Area Representation in Neural Recording Sessions") +
  scale_x_continuous(breaks = unique(full_tibble$session_id)) +  
  theme_minimal()
```

### Success Rate Estimation by Session
```{r,echo=FALSE}
full_functional_tibble %>% 
  group_by(session_id) %>% 
  summarize(success_rate = mean(success, na.rm = TRUE))
```
In the tibble result, we can observe that the trend of the success rate is increasing by session. This presents a positive increasing relationship among all sessions. 

### Success Rate Estimation by Mouse Name
```{r,echo=FALSE}
full_functional_tibble %>% 
  group_by(mouse_name) %>% 
  summarize(success_rate = mean(success, na.rm = TRUE))
```
Grouping the success rate by mouse name, the overall increasing trend is also reflected in this tibble. We can derive here that the further the session, the greater the success rate there may be. 


To look at the difference of each trial, we may look at the distribution of the contrast difference

### Contrast Difference Distribution
```{r,echo=FALSE}
full_functional_tibble %>% group_by(contrast_diff) %>% count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc))
```
We can observe from the tibble that the highest distribution percentage is 33.18% when the contrast difference is at 0.00, followed by 20.57% at 0.50, and 17.56% at 1.00. In addition, the distribution is at about 14% when the contrast difference is at 0.25 and 0.75, illustrating a roughly similar distribution. 

### Effect of Contrast Difference On Success Rate
```{r,echo=FALSE}
full_functional_tibble %>% 
  group_by(contrast_diff) %>% 
  summarize(success_rate = mean(success, na.rm = TRUE))
```
The success rate is highest when the contrast difference is at the largest value, which is 1, compared to the lowest contrast difference 0.00, which has the lowest success rate. We may conclude that greater success may be achieved if the contrast difference value is also greater. 

### Disparities Among Mice on Contrast Differences and Success Rates
```{r,echo=FALSE}
counts_df <- full_functional_tibble[c('mouse_name', 'contrast_diff')]
counts_df$contrast_diff <- as.factor(counts_df$contrast_diff)
counts <- table(counts_df)

percentages <- prop.table(counts, margin = 1)
percentages
```
In the tibble, we can observe that there is greater success rates among all mice when the contrast difference is zero. The least success that is about roughly evenly distributed among all mice is when the contrast difference is at 0.75.

### Data Visualization

Visualizing success rate change over time (trial). The success rate is binned for each 25 trials.
```{r include=FALSE}
full_functional_tibble$trial_group = cut(full_functional_tibble$trial_id, breaks = seq(0, max(full_functional_tibble$trial_id), by = 25),include.lowest = TRUE)
levels(full_functional_tibble$trial_group) <- seq(0, max(full_functional_tibble$trial_id), by = 25)[2:18]
```

### Success Rate Change Over Time For Individual Sessions
```{r,echo=FALSE}
success_rate <- aggregate(success ~ session_id + trial_group, data = full_functional_tibble, FUN = function(x) mean(x) )
ggplot(success_rate, aes(x = trial_group, y = success)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~session_id, ncol=3) +
      theme_bw()

```

In the plot, we can see that there presents roughly about the same amount of variability across all sessions. However, some sessions have smaller amounts of data. This may be due to the unequal amount of trials per session. We can assume that sessions that have smaller data amounts have lesser number of trials compared to the other sessions. 

### Success Rate Change Over Time For Individual Mice:
```{r,echo=FALSE}
success_rate <- aggregate(success ~ mouse_name + trial_group, data = full_functional_tibble, FUN = function(x) mean(x) )
ggplot(success_rate, aes(x = trial_group, y = success)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~mouse_name) +
      theme_bw()
```

In the plot, we can see that there presents roughly about the same amount of variability across all mice, with some spike changes in mouse Lederberg. We can also see that the general trend of the success rate change is roughly equal, or slightly increases a little, then decreases over time. In addition, the unequal amount of trials per session is reflected in this plot. We can assume that mice Cori and Forssmann have lesser number of trials compared to mice Hench and Lederberg.

### Visualizing The Change of Overall Neuron Spike Rate Over Time

The ``average_spike`` is the number of spikes within each number bin divided total number of neurons for each trial.

```{r,echo=FALSE}
col_names <-names(full_functional_tibble)
region_sum_subset <- col_names[grep("^region_sum", col_names)]
region_mean_subset <- col_names[grep("^region_mean", col_names)]

```
```{r,include=FALSE}
# average_spike <- full_tibble %>% group_by( session_id,trial_id) %>% summarise(mean_spike = mean(region_mean_spike))
average_spike <- full_tibble %>% group_by( session_id,trial_id) %>% summarise(mean_spike = sum(region_sum_spike)/sum(region_count))

average_spike$mouse_name <- full_functional_tibble$mouse_name
average_spike$contrast_diff <- full_functional_tibble$contrast_diff
average_spike$success <- full_functional_tibble$success
```

### Change of Overall Neuron Spike Rate for Each Session 

```{r,echo=FALSE}
ggplot(average_spike, aes(x = trial_id, y = mean_spike)) + 
  geom_line()+
  geom_smooth(method = "loess")+  # Fit a smooth spline

  facet_wrap(~session_id)
```
In the plot, we can see that Sessions 11, 8, and 9 have the greatest variability among all sessions. Sessions 4 and 18 visually have the least variability. 

### Change of Overall Neuron Spike Rate for Each Mouse 

```{r,echo=FALSE}
ggplot(average_spike, aes(x = trial_id, y = mean_spike)) + 
  geom_line()+
  geom_smooth(method = "loess")+  # Fit a smooth spline

  facet_wrap(~mouse_name)
```
Mouse Lederberg has the most variability among all mice. However, there seems to be a trend for all mice where the change of overall neuron spike rate for each mouse drastically decreases in the end trials, along with its drastically shrinking variability. 

## Dimension Reduction through PCA

We perform PCA and visualize the 2D results. 

```{r, echo = FALSE}
features = full_functional_tibble[,1:40]
scaled_features <- scale(features)
pca_result <- prcomp(scaled_features)
pc_df <- as.data.frame(pca_result$x)
pc_df$session_id <- full_functional_tibble$session_id
pc_df$mouse_name <- full_functional_tibble$mouse_name
```

The dots are colored for different session. 

```{r, echo = FALSE}
ggplot(pc_df, aes(x = PC1, y = PC2, color = session_id)) +
  geom_point() +
  labs(title = "PCA: PC1 vs PC2")
```
In this plot, we can see that there is a cluster of points on the right side of the plot, indicating a patterns of similar characteristics. In addition, we can see that the spread is greater on the x-axis, indicating that there is greater variability among these sessions. 

The dots are colored for different mouse 
```{r, echo = FALSE}
ggplot(pc_df, aes(x = PC1, y = PC2, color = mouse_name)) +
  geom_point() +
  labs(title = "PCA: PC1 vs PC2")
```

In this plot, we can see that there is a cluster of points on the right side of the plot, indicating a patterns of similar characteristics. Ledergerg, Forssmann, and Hench have a concentration of points on the right side of the plot. This may indicate that there is a similar pattern of the points observed in the plot area. Mouse Cori, on the other hand, have greater points on the left side of the plot, in addition to some points by Lederberg. This may indicate some, but not complete patterns on the left side, since it is less concentrated. Thus, we may conclude that there may be patterns, or similar characteristics that are present among all mice. The spread is also present on the x-axis, indicating greater variability among the mice.


# Section 3: Data Integration

Trials from all sessions were used first to determine its performance. 

Variables used are `session_id`, `trial_id`, signals, and the average spike rate of each time bin.

```{r echo=FALSE}
predictive_feature <- c("session_id","trial_id","contrast_right","contrast_left", "contrast_diff" ,binename)
head(full_functional_tibble[predictive_feature])
```
```{r,echo=FALSE}
predictive_dat <- full_functional_tibble[predictive_feature]
#predictive_dat$success <- as.numeric(predictive_dat$success)
predictive_dat$trial_id <- as.numeric(predictive_dat$trial_id)
label <- as.numeric(full_functional_tibble$success)
X <- model.matrix(~., predictive_dat)
```

# Section 4: Predictive Modeling

The model is trained on 80% of the trials, which will be then tested on the rest of the models. 

```{r}
# split
set.seed(134) # for reproducibility
trainIndex <- createDataPartition(label, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_df <- predictive_dat[trainIndex, ]
train_X <- X[trainIndex,]
test_df <- predictive_dat[-trainIndex, ]
test_X <- X[-trainIndex,]

train_label <- label[trainIndex]
test_label <- label[-trainIndex]
```

I decide to go with xgboost because I have lots of variables/features, I expect there are some interactions among those interactions, and I have a relative large training set to avoid overfitting. 

```{r}
xgb_model <- xgboost(data = train_X, label = train_label, objective = "binary:logistic", nrounds=10)
```

## Prediction results 
(accuracy, confusion matrix, AUROC)
```{r}
predictions <- predict(xgb_model, newdata = test_X)
predicted_labels <- as.numeric(ifelse(predictions > 0.5, 1, 0))
accuracy <- mean(predicted_labels == test_label)
accuracy

```
```{r}
conf_matrix <- confusionMatrix(as.factor(predicted_labels), as.factor(test_label))
conf_matrix$table

```
```{r}
auroc <- roc(test_label, predictions)
auroc
```

# Section 5: Prediction Performance on Test Sets

## Test the Model's Performance on 50 Random Trials from Session 18
```{r}
# split
set.seed(123) # for reproducibility
session_18_row <- which(full_functional_tibble$session_id==18)
testIndex <- sample(session_18_row, 50, replace = FALSE)
trainIndex <- 1:nrow(full_functional_tibble)
trainIndex <- trainIndex[!(trainIndex %in% testIndex)]

train_df <- predictive_dat[trainIndex, ]
train_X <- X[trainIndex,]
test_df <- predictive_dat[-trainIndex, ]
test_X <- X[-trainIndex,]

train_label <- label[trainIndex]
test_label <- label[-trainIndex]
```

## Prediction Results 
(accuracy, confusion matrix, AUROC)

```{r}
xgb_model <- xgboost(data = train_X, label = train_label, objective = "binary:logistic", nrounds=10)
predictions <- predict(xgb_model, newdata = test_X)
predicted_labels <- as.numeric(ifelse(predictions > 0.5, 1, 0))
accuracy <- mean(predicted_labels == test_label)
accuracy
conf_matrix <- confusionMatrix(as.factor(predicted_labels), as.factor(test_label))
conf_matrix$table
auroc <- roc(test_label, predictions)
auroc
```

## Test the Model's Performance on 50 Random Trials From Session 1
```{r,echo=FALSE}
# split
set.seed(123) # for reproducibility
session_1_row <- which(full_functional_tibble$session_id==1)
testIndex <- sample(session_1_row, 50, replace = FALSE)
trainIndex <- 1:nrow(full_functional_tibble)
trainIndex <- trainIndex[!(trainIndex %in% testIndex)]

train_df <- predictive_dat[trainIndex, ]
train_X <- X[trainIndex,]
test_df <- predictive_dat[-trainIndex, ]
test_X <- X[-trainIndex,]

train_label <- label[trainIndex]
test_label <- label[-trainIndex]
```

Prediction results (accuracy, confusion matrix, AUROC)

```{r,echo=FALSE}
xgb_model <- xgboost(data = train_X, label = train_label, objective = "binary:logistic", nrounds=10)
predictions <- predict(xgb_model, newdata = test_X)
predicted_labels <- as.numeric(ifelse(predictions > 0.5, 1, 0))
accuracy <- mean(predicted_labels == test_label)
accuracy
conf_matrix <- confusionMatrix(as.factor(predicted_labels), as.factor(test_label))
conf_matrix$table
auroc <- roc(test_label, predictions)
auroc
```

# Section 6 Discussion (5 pts).

  Due to time constraints, I was not able to successfully finish the project, and implement my prediction model. However, I mostly focused on Sections 1-3, and had focused on Exploratory Data Analysis methods, which I feel most confident in. While undergoing this project has helped me understand data science concepts thoroughly, I would have had more interest and passion into the creation of this project if a different dataset were to be used. If more time was given, I would have also explored other models to be implemented in my project, however the scope of my knowledge is beyond 
 
# Reference {-}

Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x